<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Как работать с LLM в 2026: workflow Addy Osmani | Сережа Рис</title>

  <!-- SEO -->
  <meta name="description" content="Сборник практик для работы с LLM в 2026: планирование до кода, context engineering, git worktrees для параллельных агентов, смена моделей. Источники: Addy Osmani, O'Reilly, incident.io.">
  <meta name="author" content="Сережа Рис">
  <meta name="keywords" content="LLM, AI, workflow, Addy Osmani, Claude, GPT, Gemini, вайбкодинг">
  <link rel="canonical" href="https://sereja.tech/blog/llm-coding-workflow-2026">

  <!-- Open Graph -->
  <meta property="og:title" content="Как работать с LLM в 2026: workflow Addy Osmani">
  <meta property="og:description" content="Разбираю workflow Addy Osmani для работы с AI-ассистентами.">
  <meta property="og:type" content="article">
  <meta property="og:locale" content="ru_RU">
  <meta property="og:url" content="https://sereja.tech/blog/llm-coding-workflow-2026">
  <meta property="og:site_name" content="Сережа Рис">
  <meta property="article:author" content="Сережа Рис">
  <meta property="article:published_time" content="2026-01-11T00:00:00+00:00">
  <meta property="article:section" content="AI">
  <meta property="article:tag" content="LLM">
  <meta property="article:tag" content="AI">
  <meta property="article:tag" content="workflow">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Как работать с LLM в 2026: workflow Addy Osmani">
  <meta name="twitter:description" content="Разбираю workflow Addy Osmani для работы с AI-ассистентами.">
  <meta name="twitter:creator" content="@riiiiiiiiss">

  <!-- JSON-LD Schema -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Как работать с LLM в 2026: workflow Addy Osmani",
    "description": "Сборник практик для работы с LLM в 2026: планирование до кода, context engineering, git worktrees для параллельных агентов.",
    "author": {
      "@type": "Person",
      "name": "Сережа Рис",
      "url": "https://sereja.tech"
    },
    "publisher": {
      "@type": "Person",
      "name": "Сережа Рис",
      "url": "https://sereja.tech"
    },
    "datePublished": "2026-01-11",
    "dateModified": "2026-01-11",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://sereja.tech/blog/llm-coding-workflow-2026"
    },
    "wordCount": 950,
    "articleSection": "AI",
    "keywords": ["LLM", "AI", "workflow", "Addy Osmani", "Claude", "GPT"],
    "inLanguage": "ru-RU"
  }
  </script>

  <style>
    body {
      font-family: monospace;
      max-width: 600px;
      margin: 0 auto;
      padding: 20px;
      line-height: 1.6;
      background: #fff;
      color: #000;
    }
    a { color: #0000EE; text-decoration: underline; }
    a:visited { color: #551A8B; }
    h1 { font-size: 24px; margin-bottom: 8px; line-height: 1.3; }
    h2 { font-size: 18px; margin-top: 30px; margin-bottom: 10px; }
    p { margin-bottom: 15px; }
    .author { color: #666; font-size: 13px; margin-bottom: 24px; }
    .intro { color: #666; margin-bottom: 8px; }
    .intro:last-of-type { margin-bottom: 24px; }

    .callout {
      border: 1px solid #000;
      padding: 12px 16px;
      margin: 20px 0;
    }
    .callout.insight { border-left: 3px solid #060; }
    .callout strong { display: block; margin-bottom: 4px; }
    .callout p { margin-bottom: 0; }

    ul { margin: 12px 0; padding: 0 0 0 1.2em; }
    li { margin-bottom: 4px; }

    .sources { margin-top: 40px; padding-top: 20px; border-top: 1px solid #000; }
    .sources h3 { font-size: 14px; margin-bottom: 8px; }
    .sources ul { list-style: none; padding: 0; }
    .sources li { margin-bottom: 4px; }

    footer { margin-top: 30px; text-align: center; font-size: 13px; color: #666; }
  </style>
</head>
<body>
  <p><a href="/blog/">&larr; Блог</a></p>
  <article>
    <h1>Как работать с LLM в 2026: workflow Addy Osmani</h1>
    <p class="author">Сережа Рис · 11 января 2026</p>

    <p class="intro">Addy Osmani из Google опубликовал свой подход к работе с AI-ассистентами.</p>
    <p class="intro">Собрал его инсайты плюс практики из других источников — O'Reilly, incident.io, Builder.io.</p>
    <p class="intro">Получился сборник того, что реально работает в 2026.</p>

    <h2>Планируй до кода</h2>

    <p>"Waterfall за 15 минут" — так Osmani называет подход. Перед первой строкой кода пишешь документ: что делаем, что не делаем, какие edge cases. Harper Reed идёт дальше — у него два файла: <code>spec.md</code> с требованиями и <code>plan.md</code> с пошаговым планом.</p>

    <p>Сначала обсуждаешь задачу с AI как с архитектором — уточняешь требования, проверяешь понимание. Потом код. Без этого модель генерирует "в молоко".</p>

    <p>В Claude Code — Plan Mode (Shift+Tab дважды). Cursor выполняет промпты из файла последовательно. Думай до того, как пишешь.</p>

    <h2>Декомпозиция: один запрос = одна задача</h2>

    <p>Одна функция, один баг, одна фича за промпт. Не больше. Osmani называет это "iterative chunks".</p>

    <p>Большие запросы ломают модель — она путается, дублирует код, забывает начало промпта. Порог где-то на 150-200 словах. После него качество падает резко.</p>

    <p>Практический паттерн: разбей задачу на 5-7 шагов, каждый шаг — отдельный промпт. Между промптами проверяй результат. Если что-то пошло не так — откатывай и переформулируй, пока контекст не засорился.</p>

    <h2>Context engineering</h2>

    <p>Термин из отчёта O'Reilly Radar 2026: context engineering — это управление тем, что модель знает о проекте. Prompt engineering — как спрашиваешь, context engineering — что модель видит.</p>

    <p>Инструменты для упаковки контекста: <code>gitingest</code>, <code>repo2txt</code>, Context7. Они дампят нужные части кодовой базы в формат, который AI может переварить. Модель не знает твою архитектуру — покажи ей.</p>

    <p>Но контекст надо фильтровать. Cursor делает это через локальный индекс с semantic search. Windsurf использует "Fast Context" для выборки по сотням файлов. Общий принцип: релевантный контекст улучшает ответы, нерелевантный — размывает.</p>

    <p>CLAUDE.md — файл с правилами проекта. Стиль кода, конвенции, запреты. В Copilot есть custom instructions. Cursor поддерживает .cursorrules. Смысл один: формализуй то, что модель должна знать всегда.</p>

    <h2>Смена моделей</h2>

    <p>"Model musical chairs" — застрял на Claude, переключись на Gemini. Свежий взгляд часто ломает затык.</p>

    <p>Claude — мой выбор для сложной архитектуры и логики. GPT-5.2 быстрее справляется с рутиной: бойлерплейт, миграции, однотипные тесты. Gemini 3 Flash (декабрь 2025) работает арбитром — быстрый и дешёвый. Когда нужно решать, а не генерировать — GPT-5 в режиме thinking.</p>

    <p>Кросс-ревью: GPT критикует код Claude. На прошлой неделе GPT нашёл race condition в async-хендлере, который Claude пропустил. Дешевле, чем баг в проде.</p>

    <h2>Git worktrees для параллельных агентов</h2>

    <p>Практика, которая взорвала 2025-й. Git worktrees держат несколько веток в разных папках одновременно — каждый агент в своей песочнице.</p>

    <p>Incident.io запускает 4-5 Claude-агентов параллельно, каждый в своём worktree. Workmux от raine.dev связывает worktrees с tmux — получается дашборд: видишь все задачи, переключаешься между агентами в одном терминале.</p>

    <p>Зачем это нужно: агенты не мешают друг другу. Один может сломать типы в своей ветке — это не аффектит остальных. Можно параллельно пробовать три архитектурных подхода и потом сравнить.</p>

    <p>Базовый workflow: главный агент генерирует список задач, потом <code>workmux add</code> создаёт worktree для каждой. Агенты работают параллельно, ты ревьюишь и мержишь через <code>workmux merge --rebase</code>.</p>

    <h2>Субагенты для изоляции контекста</h2>

    <p>Другой подход к параллелизму — субагенты. В Claude Code это Task tool с разными типами агентов: Debugger Agent, Security Agent, Documentation Agent.</p>

    <p>Преимущество: субагент работает в чистом контексте. Основная сессия не засоряется. После завершения субагент возвращает результат, а его внутренний контекст выбрасывается.</p>

    <p>Когда использовать: задача самодостаточная и не требует истории разговора. Хочешь сэкономить на токенах — запусти на Haiku. Контекст основной сессии забит — делегируй.</p>

    <h2>Git-дисциплина</h2>

    <p>Коммить после каждой мини-задачи. Это точки сохранения для отката. Osmani формулирует жёстко: "Never commit code you can't explain."</p>

    <p>AI генерирует быстро — легко накопить гору изменений и потерять контроль. Частые коммиты держат историю читаемой. Если что-то сломалось — откат на один коммит назад, а не раскопки в 500-строчном диффе.</p>

    <h2>Senior-скиллы решают</h2>

    <p>O'Reilly Radar 2026: роль разработчика сместилась от синтаксиса к архитектуре и ревью. Эпоха "10x engineer" закончилась — началась "100x organization".</p>

    <p>AI усиливает экспертизу. Архитектура, trade-offs, управление сложностью — это твоё. Модель быстрее генерирует, значит строже дисциплина. Тесты, ревью, стандарты — важнее, чем раньше.</p>

    <div class="callout insight">
      <strong>Главный вывод</strong>
      <p>Относись к AI как к джуниору с суперсилой скорости. Проверяй всё. Планируй до кода. Коммить часто. И помни: ты остаёшься ответственным инженером.</p>
    </div>

    <div class="sources">
      <h3>Источники</h3>
      <ul>
        <li><a href="https://addyo.substack.com/p/my-llm-coding-workflow-going-into" target="_blank">My LLM coding workflow going into 2026 — Addy Osmani</a></li>
        <li><a href="https://www.oreilly.com/radar/signals-for-2026/" target="_blank">Signals for 2026 — O'Reilly Radar</a></li>
        <li><a href="https://incident.io/blog/shipping-faster-with-claude-code-and-git-worktrees" target="_blank">Shipping faster with Claude Code and Git Worktrees — incident.io</a></li>
        <li><a href="https://raine.dev/blog/git-worktrees-parallel-agents/" target="_blank">Using git worktrees to parallelize AI coding — raine.dev</a></li>
        <li><a href="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/" target="_blank">My LLM codegen workflow — Harper Reed</a></li>
        <li><a href="https://thinkpeak.ai/coding-with-llms-2026-strategy/" target="_blank">Coding with LLMs in 2026: Strategy — ThinkPeak</a></li>
        <li><a href="https://www.builder.io/blog/claude-code" target="_blank">How I use Claude Code — Builder.io</a></li>
        <li><a href="https://www.dayzero.live/software-engineering/the-state-of-ai-pair-programming-in-2026" target="_blank">The State of AI Pair Programming in 2026 — DayZero</a></li>
      </ul>
    </div>

    <footer>
      Январь 2026
    </footer>
  </article>
</body>
</html>
