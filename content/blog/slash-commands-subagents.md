---
title: "Почему model: в slash-командах — это ловушка"
date: 2026-01-10
description: "Разбираюсь почему model: haiku в командах Claude Code не экономит токены. Commands, Skills и Agents — в чём разница и как делегировать правильно."
tags: ["claude code", "субагенты"]
section: Claude Code
knowledge:
  problem: "Параметр model: в slash-командах Claude Code не экономит токены — текст всё равно попадает в основной контекст"
  solution: "Использовать паттерн 'тонкий диспетчер' — команда вызывает Task tool для запуска отдельного субагента"
  pattern: "thin-dispatcher-subagent"
  tools: ["Claude Code", "Task tool", "Slash Commands"]
  takeaways:
    - "Commands и Skills вливают текст в основной контекст, только Agents работают изолированно"
    - "169K токенов в основном контексте vs 21K через отдельного агента — разница в 8 раз"
    - "model: в frontmatter работает только с полными названиями моделей, алиасы игнорируются"
    - "После создания агента нужно перезапустить сессию — изменения подхватываются при старте"
  metrics:
    main_context_tokens: 169000
    subagent_context_tokens: 21000
    token_reduction_factor: 8
  related:
    - slug: "claude-code-token-optimization"
      relation: "Оптимизация расхода токенов в Claude Code"
---

Решил сэкономить на токенах. Сделал команду `/readme` с `model: haiku`.

Запустил — вроде работает.

Только потом понял, что Opus всё это время делал работу сам.

## Что я хотел

Идея простая: README генерировать на дешёвой модели. Haiku справится, зачем платить за Opus? Добавил в frontmatter команды `model: haiku` — логично же.

А оно не так работает.

Когда запускаешь slash-команду, её текст просто вливается в основной контекст. Какая модель этот контекст обрабатывает — та и выполняет. `model:` в frontmatter меняет модель, но текст команды всё равно летит в общий котёл.

```
/readme → текст команды вливается в контекст → Opus читает и делает
```

169 тысяч токенов в контексте. А если через отдельного агента — 21 тысяча. В восемь раз меньше.

## Три механизма, которые путают

В Claude Code есть три штуки с похожими названиями. Выглядят одинаково, работают по-разному.

| Что | Как работает | Отдельная модель? |
|-----|--------------|-------------------|
| Commands | Текст вливается в контекст | Нет |
| Skills | То же самое, через Skill tool | Нет |
| Agents | Task tool запускает отдельный процесс | Да |

{{< callout warning "Нюанс про model: в командах" >}}
Работает только с полными названиями моделей типа `claude-sonnet-4-5-20250929`. Алиасы вроде `sonnet` или `haiku` игнорируются. Но даже если указать полное название — изоляции не будет. Текст всё равно попадёт в общий контекст.
{{< /callout >}}

## Как на самом деле делегировать

{{< callout insight >}}
Хочешь чтобы Haiku работал отдельно — вызывай Task tool явно. Commands и Skills для этого не подходят, они просто способ подсунуть текст в контекст.
{{< /callout >}}

Решение называется «тонкий диспетчер». Команда ничего не делает сама — только говорит вызвать нужного агента.

```
/readme → диспетчер → Task tool → Haiku-агент работает отдельно
```

```markdown
# ~/.claude/commands/readme.md
---
description: Генерация README через Haiku
---
Немедленно запусти субагента.

**Параметры Task tool:**
- subagent_type: "readme-writer"
- model: "haiku"
- prompt: "Сгенерируй README.md"

**Правила:**
1. Сам ничего не генерируй
2. Только запусти агента и верни результат
```

Сам агент лежит в `.claude/agents/readme-writer.md`. Там уже написано что делать и как. Команда просто его триггерит.

## Когда это нужно

Имеет смысл когда:
- Задача самодостаточная, история чата не нужна
- Хочешь использовать дешёвую модель
- Контекст уже забит, а задача простая

Не парься когда:
- Задача мелкая, разница в токенах погоды не делает
- Агенту нужен контекст разговора
- Opus и так справляется, экономить не на чем

И да — после создания агента перезапусти сессию. Изменения подхватываются только при старте.

## Источники

- [Issue #4937](https://github.com/anthropics/claude-code/issues/4937) — про полные названия моделей
- [Issue #10993](https://github.com/anthropics/claude-code/issues/10993) — как работает CLAUDE_CODE_SUBAGENT_MODEL
- [Model Configuration](https://code.claude.com/docs/en/model-config) — официальная документация
- [Context Engineering](https://jxnl.co/writing/2025/08/29/context-engineering-slash-commands-subagents/) — откуда цифры 169K vs 21K
