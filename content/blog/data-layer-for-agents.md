---
title: "Один JSON кормит всех: как строить data layer для агентов"
date: 2026-02-28
description: "Как Claude Code за одну сессию спроектировал схему, получил API-ключ через Chrome и собрал 70 видео в videos.json — единый источник данных для всех агентов."
tags: ["claude-code", "youtube-api", "mcp", "автоматизация", "инфраструктура"]
image: "/images/blog/data-layer-for-agents-preview.png"
knowledge:
  problem: "Несколько агентов из разных проектов дёргают YouTube API по-своему, дублируя работу"
  solution: "Один коллектор собирает данные в единый JSON-файл, который все агенты читают напрямую"
  pattern: "single-source-data-layer"
  tools: ["Claude Code", "YouTube API v3", "Exa MCP", "Chrome DevTools MCP", "launchd", "jq"]
  takeaways:
    - "playlistItems.list + videos.list в 100 раз эффективнее search.list по квотам YouTube API"
    - "70 видео обновляются за 3-5 единиц из 10 000 дневной квоты — 0.05% лимита"
    - "JSON выбран вместо SQLite: cat | jq работает без зависимостей из любого агента"
    - "Chrome DevTools MCP получил API-ключ через браузер без ручных кликов"
    - "Вся инфраструктура построена за одну сессию Claude Code"
  metrics:
    videos_count: 70
    subscribers: 3360
    total_views: 182000
    api_units_per_run: 5
    daily_quota: 10000
    script_lines: 184
  prerequisites: ["Аккаунт Google Cloud Console", "Chrome DevTools MCP"]
  related:
    - slug: "chrome-devtools-mcp-setup"
      relation: "настройка Chrome DevTools MCP, использованного для получения API-ключа"
    - slug: "blog-post-pipeline"
      relation: "пример другой инфраструктуры, построенной агентами для агентов"
---

Claude Code за одну сессию построил полноценную YouTube-инфраструктуру: исследовал квоты API, спроектировал схему данных, получил API-ключ через браузер, написал скрипт-коллектор и настроил ежедневный запуск. Результат --- файл `videos.json` с 70 видео, 3360 подписчиками и 182K просмотрами. Этот файл теперь кормит данными агентов из совершенно разных проектов.

## Зачем мне YouTube-база

У меня несколько агентов в разных проектах, которые работают с YouTube-данными. [Видео-пайплайн](/blog/video-pipeline-claude-code/) при публикации урока хочет знать, какие видео уже есть на канале. Агент для идей блог-постов сканирует темы видео, чтобы не повторяться. Агент для обложек проверяет, [какие thumbnail уже сгенерированы](/blog/youtube-thumbnails-html-code/).

Раньше каждый из них дёргал YouTube API по-своему. Или вообще не дёргал --- я вручную копировал данные. Это нарушает мой принцип: если процесс повторяется больше двух раз --- делегировать.

Я решил: нужен единый data layer. Один файл, один коллектор, много потребителей.

## Приём 1: Exa research для квот API

YouTube Data API v3 даёт 10 000 единиц квоты в день --- звучит щедро, пока не узнаешь, что один `search.list` съедает 100 единиц.

Я попросил агента разобраться:

{{< callout type="insight" >}}
**Промпт для Claude Code (Opus 4.6) с Exa MCP:**

Проведи комплексное исследование на предмет лучших практик для этой проблемы используя exa mcp
{{< /callout >}}

Агент через Exa AI нашёл официальную документацию по квотам и вернул ключевое: `search.list` стоит 100 единиц за запрос, а `playlistItems.list` + `videos.list` --- по 1 единице за 50 видео. Разница в 100 раз по эффективности.

Это и определило подход. Вместо поиска видео через search --- агент берёт uploads playlist канала и пакетно запрашивает метаданные. На мои 70 видео уходит ~3-5 единиц из 10 000 доступных. Можно обновлять хоть каждый час.

## Приём 2: brainstorming через skill

С квотами разобрались --- теперь схема данных. У меня есть skill `/brainstorming` --- Q&A сессия, где агент задаёт вопросы перед тем как писать код. Помогает не бросаться в реализацию, а зафиксировать решения до первой строчки.

{{< callout type="insight" >}}
**Промпт для Claude Code (Opus 4.6):**

Есть issue --- там план того что надо реализовать. /brainstorming
{{< /callout >}}

Агент задал правильные вопросы:

- **JSON vs SQLite?** JSON. Потому что `cat videos.json | jq` работает из любого агента без зависимостей. А `json.load()` --- две строчки на Python. SQLite требует драйвер и знание SQL.
- **Где хранить метку обновления статистики?** Отдельно в `stats.updated_at`. Видео публикуется один раз, а просмотры меняются каждый день.
- **Как парсить главы?** Regex из description: `(\d{1,2}:\d{2}(?::\d{2})?)\s+(.+)`. 36 из 70 видео имеют таймкоды в описании.

Зафиксировали до кода --- агент не тратит время на переделки.

## Архитектура: один коллектор, один файл

Вот что получилось:

```
┌─────────────────┐
│  YouTube API v3 │
│  (10,000 units) │
└────────┬────────┘
         │ ~3-5 units/day
         ▼
┌─────────────────┐     ┌──────────────┐
│ update_stats.py │────▶│ videos.json  │
│ (launchd 10:00) │     │ 70 videos    │
└─────────────────┘     │ 3360 subs    │
                        │ 182K views   │
                        └──────┬───────┘
               ┌───────────────┼───────────────┐
               ▼               ▼               ▼
        ┌─────────────┐ ┌───────────┐ ┌──────────────┐
        │ lesson-     │ │ blog-     │ │ thumbnail-   │
        │ pipeline    │ │ ideas     │ │ generator    │
        │             │ │           │ │              │
        │ cat | jq    │ │ json.load │ │ cat | jq     │
        └─────────────┘ └───────────┘ └──────────────┘
```

Скрипт `update_stats.py` делает три вызова API за один запуск:

1. `channels.list` --- подписчики, просмотры, ID плейлиста загрузок
2. `playlistItems.list` --- все ID видео с канала
3. `videos.list` (пакетами по 50) --- метаданные и статистика

Новые видео получают полную запись: заголовок, описание, теги, длительность, главы. Существующие --- только обновление счётчиков просмотров, лайков, комментариев.

## Приём 3: Chrome DevTools MCP для API-ключа

У меня не было API-ключа YouTube. Обычно это значит: открой Google Cloud Console, создай проект, включи API, создай credentials... Минут 10 ручных кликов.

Но у меня настроен [Chrome DevTools MCP](/blog/chrome-devtools-mcp-setup/) --- агент умеет [управлять браузером](/blog/chrome-devtools-mcp/): кликать, вводить текст, читать страницы.

{{< callout type="insight" >}}
**Промпт для Claude Code (Opus 4.6) с Chrome DevTools MCP:**

Нет ключа --- получи его сам через девтулс мсп
{{< /callout >}}

Агент открыл Google Cloud Console в Chrome. Зашёл в API & Services. Включил YouTube Data API v3. Создал API key. Добавил ограничение по API (только YouTube). Скопировал ключ в `.env`.

Всё кликами через UI. Я смотрел в терминал, как агент делает скриншоты страниц, находит кнопки и жмёт по ним. Честно, ожидал что где-то застрянет --- но нет, просто сработало. [Chrome DevTools MCP](https://github.com/ChromeDevTools/chrome-devtools-mcp) --- open-source проект от Google (сентябрь 2025, 27K звёзд на GitHub).

## launchd, а не GitHub Actions

`videos.json` --- локальный файл на моём MacBook. Агенты читают его через `cat` или `json.load()` прямо из файловой системы.

GitHub Actions потребовали бы: хранить ключ в secrets, пушить файл в repo, тянуть его обратно. Лишний слой для задачи, которая работает на одной машине.

launchd --- встроенный планировщик macOS. Один plist-файл:

```xml
<key>StartCalendarInterval</key>
<dict>
    <key>Hour</key>
    <integer>10</integer>
    <key>Minute</key>
    <integer>0</integer>
</dict>
```

Каждый день в 10 утра скрипт обновляет данные. Логи пишутся в `~/Library/Logs/stats-youtube.log`. Если MacBook выключен --- запустится при следующем включении.

## Что внутри videos.json

На канале [@serejaris](https://youtube.com/@serejaris) 70 видео, самое старое --- апрель 2020. Для каждого хранится:

```json
{
  "id": "8oJQyTai2X4",
  "title": "GEMINI 3.1 PRO классно вайбкодит?",
  "published_at": "2026-02-19T22:42:10Z",
  "duration": "PT1H36M",
  "tags": ["вайбкодинг", "gemini"],
  "chapters": [
    {"time": "00:00", "title": "Первый запуск и SVG-анимация"},
    {"time": "07:23", "title": "Тест SVG-анимаций"}
  ],
  "stats": {
    "views": 5162,
    "likes": 99,
    "comments": 30,
    "updated_at": "2026-02-28T11:10:48Z"
  }
}
```

Любой агент может достать нужное одной командой:

```bash
# Топ-3 видео по просмотрам
jq '.videos | sort_by(-.stats.views) | .[0:3] | .[].title' videos.json

# Видео с тегом "claude-code"
jq '.videos[] | select(.tags[] | test("claude"; "i")) | .title' videos.json
```

Топ канала на сегодня: OpenCode (12.5K просмотров), Claude Code гайд (10.5K), ИИ-мозг на Obsidian (10.2K).

## Одна сессия --- полная инфраструктура

Одна сессия Claude Code --- не "за 15 минут", а полноценная рабочая сессия с исследованием, проектированием и реализацией. Вот что агент сделал:

1. Исследовал квоты YouTube API через Exa
2. Спроектировал схему через brainstorming
3. Получил API-ключ через Chrome DevTools MCP
4. Написал `update_stats.py` (184 строки Python)
5. Создал launchd plist для ежедневного запуска
6. Запустил первый полный сбор данных

Я не открывал ни один файл. Не писал ни строчки кода. Не ходил в Google Cloud Console руками. Промпты --- это весь мой вклад.

[Addy Osmani](https://medium.com/@addyosmani/my-llm-coding-workflow-going-into-2026-52fe1681325e) из Google в декабре 2025 писал, что ~90% кода Claude Code написано самим Claude Code. По-моему, дело не в модели --- а в инфраструктуре вокруг неё: skills для brainstorming, MCP для браузера, Exa для research.

## Строй инфраструктуру для агентов

Агенты полезнее, когда у них есть готовые данные. Не "доступ к API" --- а структурированный файл, который можно прочитать за миллисекунды.

[Пайплайн для статей](/blog/blog-post-pipeline/) работает так же: агент строит инфраструктуру, которой потом пользуются другие агенты. Агент достаёт данные для агентов.

Начните с data layer. Соберите в один файл то, к чему агенты обращаются чаще всего --- YouTube-статистика, список проектов, история коммитов. Один коллектор, один JSON, много потребителей.

## FAQ

### Почему JSON, а не SQLite?

Простота доступа. `cat videos.json | jq` работает без зависимостей. `json.load()` --- две строчки Python. Любой агент из любого проекта может прочитать файл, не устанавливая драйверы. Для 70 видео реляционная база --- избыточна.

### Сколько стоит YouTube API?

Бесплатно. YouTube Data API v3 даёт 10 000 единиц квоты в день. Мой скрипт тратит 3-5 единиц за запуск --- это 0.05% от лимита. Ключ создаётся в Google Cloud Console без привязки карты.

### Можно ли повторить получение API-ключа через Chrome DevTools MCP?

Да, если у вас настроен [Chrome DevTools MCP](/blog/chrome-devtools-mcp-setup/) и вы авторизованы в Google Cloud Console в Chrome. Агент видит интерфейс через скриншоты и кликает по элементам. Но первоначальную авторизацию в Google нужно сделать вручную --- MCP не вводит пароли.
