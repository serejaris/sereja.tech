---
title: "Kimi K2.5 — китайская модель, которая обошла GPT-5 и Claude на бенчмарках"
date: 2026-01-27
description: "Moonshot AI выпустили K2.5 с 256K контекстом и ценой в 5 раз ниже Claude. Разбираюсь, где реально полезна и стоит ли переключаться."
tags: ["llm", "kimi"]
knowledge:
  problem: "Claude дорог для рутинных batch-задач с большим объёмом токенов."
  solution: "Kimi K2.5 за $0.60/M токенов закрывает рутинные пайплайны и batch-операции при достаточном качестве."
  pattern: "cheap-model-for-batch"
  tools: ["Kimi K2.5", "Claude Opus 4.5", "OpenRouter", "Kimi CLI"]
  takeaways:
    - "K2.5 стоит $0.60/M токенов vs $3.00/M у Claude Sonnet — в 5 раз дешевле"
    - "256K контекст, 50.2% на Humanity's Last Exam (выше GPT-5.2 и Claude Opus 4.5)"
    - "200-300 вызовов инструментов подряд без потери качества (agent swarm)"
    - "Парсинг 80MB логов за 40 секунд и $0.12 — на Claude вышло бы около доллара"
    - "API совместим с OpenAI, доступен через OpenRouter как moonshotai/kimi-k2.5"
  metrics:
    cost_per_million_tokens: 0.60
    context_window_k: 256
    hle_score_percent: 50.2
  related:
    - slug: "gemini-3-1-pro-svg-animations"
      relation: "оба — специализированные модели: Kimi для batch, Gemini для SVG"
---

Moonshot AI сегодня обновили модель на kimi.com без анонсов. Просто тихо заменили K2 на K2.5. А через пару часов появились бенчмарки на Humanity's Last Exam — и там K2.5 набрала 50.2%, обойдя GPT-5.2 (48.1%) и Claude Opus 4.5 (47.8%).

Первая китайская модель на первом месте в этом бенчмарке.

## Три ставки Moonshot

**Визуальный кодинг.** Скармливаешь скриншот — получаешь рабочий код. Я дал K2.5 макет страницы из Figma, и она выдала React-компонент с Tailwind. Claude обычно просит уточнений, тут сработало с первого раза.

**Agent swarm.** Модель держит 200-300 вызовов инструментов подряд без потери качества. Moonshot называют это "рой агентов" — когда одна задача разбивается на подзадачи и модель сама их координирует.

**Цена.** $0.60 за миллион токенов на входе. Claude Sonnet берёт $3.00. Контекст — 256K токенов. Для задач с большими объёмами данных это меняет экономику.

## Где я буду использовать

{{< callout type="insight" >}}
Погонял K2.5 на парсинге логов телеграм-бота. 80MB файл, 200k строк. Справилась за 40 секунд, потратил $0.12. На Claude вышло бы около доллара.
{{< /callout >}}

**Рутинные пайплайны.** CI/CD скрипты, обработка файлов, миграции данных. Качество достаточное, цена низкая.

Прототипирование по скриншотам — показал макет, получил вёрстку. Не финальный код, но рабочую основу.

**Batch-операции** с большими объёмами. Анализ документов, классификация, extraction. По-моему, здесь K2.5 выгоднее всего.

## Где оставлю Claude

Для текстов, диалогов и сложного рефакторинга — Opus 4.5. Разница в качестве рассуждений заметна сразу.

По скорости K2.5 тоже проигрывает: 50-80 токенов в секунду против 187 у GPT-5.2. В чате это ощущается.

Документация в основном на китайском. Базовые гайды есть на английском, но если копнуть глубже — переводчик в помощь.

## Подключение

API совместим с OpenAI. Регистрация на platform.moonshot.ai, ключ, base URL `api.moonshot.cn/v1`. Или через OpenRouter — там модель называется `moonshotai/kimi-k2.5`.

Есть Kimi CLI для терминала. Ctrl+K переключает между шеллом и агентом. Почти 4k звёзд на GitHub.

## Итог

Claude Code остаётся главным инструментом. Но для рутины с высоким объёмом токенов добавил K2.5 в арсенал. Экономия заметная, качество для таких задач достаточное.

---

*Это тестовый пост — проверяю воркфлоу для быстрого написания новостей через Claude Code с Exa research.*

## Источники

- [OfficeChai — Kimi K2.5 Benchmarks](https://officechai.com/ai/moonshot-ai-releases-open-kimi-k2-5-model-beats-all-us-models-on-humanitys-last-exam-browsecomp-benchmarks/)
- [Moonshot AI Platform](https://platform.moonshot.ai)
- [GitHub — Kimi CLI](https://github.com/MoonshotAI/kimi-cli)
- [OpenRouter — Kimi K2.5](https://openrouter.ai/moonshotai/kimi-k2.5)
