---
title: "Two-Stage AI Pipeline: как платить вдвое меньше за генерацию"
date: 2026-01-23
description: "Паттерн разделения LLM-запросов на быструю модель для извлечения и качественную для генерации. Реальный пример из Telegram-бота дайджестов."
tags: ["llm", "gemini", "оптимизация"]
knowledge:
  problem: "Pro-модель тратила 80% токенов на извлечение тем из JSON, счёт $87/месяц за дайджесты"
  solution: "Разделение на Flash для extraction и Pro для генерации снизило стоимость с $87 до $35 в месяц"
  pattern: "two-stage-extraction-generation"
  tools: ["Gemini Flash", "Gemini Pro", "Pydantic", "Claude Code"]
  takeaways:
    - "Flash ($0.50/1M токенов) в 4 раза дешевле Pro ($2/1M) для extraction"
    - "Контекст Pro сжался с 80-120K до 8-12K токенов после разделения"
    - "Стоимость дайджеста снизилась с $2.5-3.5 до $1.0-1.2"
    - "Structured output через Pydantic + response_schema гарантирует валидный JSON"
    - "Flash retry с эскалацией лимитов (16K→32K→65K) сработал 2 раза за месяц"
  metrics:
    cost_before_usd: 87
    cost_after_usd: 35
    digests_per_month: 30
  related:
    - slug: "digest-subagents-mapreduce"
      relation: "альтернативный подход к генерации дайджестов через субагентов"
---

$87 в месяц на дайджесты чата. Посмотрел логи — Pro-модель тратит 80% токенов на поиск тем в JSON. Разделил на два этапа. Теперь $35.

## Проблема

Делаю бота для дайджестов чата @vibecod3rs. 200-400 сообщений в день. На выходе — структурированный дайджест с ресурсами, решениями, инструментами.

Первая версия: всё в Pro. Она и темы извлекает, и текст пишет. Работает, но счёт за январь:

- 80-120K токенов на вход (зависит от активности чата)
- $2.5-3.5 за дайджест
- 30 дайджестов → $87

Pro отлично пишет. Но $2/1M токенов за то, чтобы найти в JSON нужные поля и сгруппировать? Дорого.

## Решение

Два этапа вместо одного:

{{< callout type="insight" >}}
Stage 1 (Flash): найди все темы в сообщениях, верни JSON.
Stage 2 (Pro): вот 12 тем — напиши из них дайджест.
{{< /callout >}}

Flash стоит $0.50/1M — в 4 раза дешевле Pro. Справляется с extraction без проблем. Structured output через Pydantic гарантирует формат — Gemini API поддерживает `response_schema` с ноября 2025.

Pro получает готовый список из 10-15 тем вместо сотен сообщений. Контекст сжался с 100K до 8-12K токенов.

## Реализация

Написал Claude Code на Opus 4.5:

{{< callout type="insight" >}}
Раздели генерацию дайджеста на два этапа. Stage 1: Flash извлекает темы из сообщений и возвращает JSON с категориями (resource, solution, insight, tool). Stage 2: Pro получает готовые темы и пишет финальный текст. Используй Pydantic-схему для structured output.
{{< /callout >}}

Агент сделал:
1. Создал `TopicsResponse` схему с полями category, title, summary, url
2. Настроил Gemini API с `response_schema` — JSON гарантированно валидный
3. Разделил `DigestGenerator` на `_extract_topics()` и финальную генерацию

## Retry с эскалацией

Flash иногда обрезает JSON на больших входах. Попросил добавить retry:

{{< callout type="insight" >}}
Добавь эскалацию лимитов при обрезке: 16K → 32K → 65K токенов. Если TokenLimitExceeded — повтори с бóльшим лимитом.
{{< /callout >}}

За месяц (31 дайджест) retry сработал дважды. Оба раза хватило 32K.

## Результат

| Метрика | До | После |
|---------|-----|-------|
| Токены Pro | 80-120K | 8-12K |
| Стоимость/дайджест | $2.5-3.5 | $1.0-1.2 |
| Январь 2026 | $87 | $35 |

Бонус: Pro пишет чище с готовыми данными. Без шума из 300 сообщений — меньше "воды" в итоговом тексте.

## Когда применять

Паттерн работает если:

1. **Extraction отделим от generation** — сначала найти, потом написать
2. **Входные данные большие** — сотни документов, логи, чаты
3. **Структура известна** — опишешь Pydantic-моделью

Не подходит для суммаризации (нужен весь контекст) и коротких запросов (overhead не окупится).

## Источники

- [OverFill: Two-Stage Models for Efficient LLM Decoding](https://arxiv.org/abs/2508.08446) — академический подход к разделению prefill и decode
- [xRouter: Cost-Aware LLM Orchestration](https://arxiv.org/html/2510.08439v1) — RL для выбора модели под задачу
- [The Economics of RAG: Cost Optimization](https://thedataguy.pro/blog/2025/07/the-economics-of-rag-cost-optimization-for-production-systems/) — стратегии оптимизации затрат в RAG
