---
title: "MapReduce для субагентов: как обработать 12800 строк и не потерять контекст"
date: 2026-01-14
description: "Контекст закончился на середине файла. Решение — разбить работу между субагентами параллельно. Паттерн MapReduce для Claude Code."
tags: ["claude code", "субагенты"]
section: Claude Code
knowledge:
  problem: "Контекст Claude Code переполняется при последовательном чтении файлов больше 5000 строк."
  solution: "Паттерн MapReduce — разбить файл между параллельными субагентами, каждый со своим контекстом в 200K токенов."
  pattern: "mapreduce-subagents"
  tools: ["Claude Code", "Task tool", "Opus 4.5"]
  takeaways:
    - "3 субагента = 3 отдельных контекста по 200K токенов"
    - "12800 строк субтитров → 460 строк конспекта, компрессия 28:1"
    - "Каждый субагент стоит ~20K токенов на запуск — overhead для маленьких задач"
    - "Последовательное чтение заняло 100% контекста и не завершилось, MapReduce — ~30% за 3 минуты"
    - "Подходит когда задача разбивается на независимые куски и результаты можно склеить"
  metrics:
    input_lines: 12800
    output_lines: 460
    compression_ratio: "28:1"
    execution_time_min: 3
    subagent_overhead_tokens: 20000
  related:
    - slug: "map-reduce-youtube-metadata"
      relation: "применение MapReduce к YouTube-метаданным"
    - slug: "digest-subagents-mapreduce"
      relation: "применение MapReduce к дайджестам чата"
---

Файл субтитров — 12 тысяч строк. Читаю кусками по тысяче.

На восьмом куске — Context limit reached.

А я ещё не начал генерировать конспект.

## Проблема: контекст — жёсткий лимит

У Opus 4.5 окно в 200 тысяч токенов. Звучит много — пока не начнёшь читать большие файлы.

Мне нужно было сделать конспект двухчасового урока по вайбкодингу. Файл субтитров — 12800 строк. Каждое чтение по тысяче строк съедает процентов десять контекста. Плюс системный промпт, история чата, инструменты.

Восемь чтений — и 185k из 200k занято. Работа не начата, а данные уже не влезают.

## Идея: каждый субагент — это отдельные 200k

Task tool запускает субагента в изолированном процессе. У него свой контекст. Свои 200 тысяч токенов.

{{< callout insight >}}
Anthropic в своей research-системе обнаружили: разбивать работу между субагентами и потом собирать результаты — эффективнее, чем запихивать всё в один большой контекст. Даже если модель технически вмещает.
{{< /callout >}}

Три субагента — это три отдельных контекста по 200k. Каждый читает свой кусок файла, делает свою часть работы, возвращает результат. Главный агент только собирает.

## Паттерн MapReduce

Название из распределённых вычислений: Map раздаёт задачи, Reduce собирает результаты.

```
[subtitles.srt — 12800 строк]
            │
    ┌───────┼───────┐
    ▼       ▼       ▼
[Agent 1] [Agent 2] [Agent 3]
Ch. 1-9   Ch. 10-18 Ch. 19-26
    │       │       │
    ▼       ▼       ▼
[Summary] [Summary] [Summary]
    └───────┼───────┘
            ▼
    [Main: объединить]
            │
            ▼
    [summary.md готов]
```

Каждый субагент читает только свой диапазон — не знает про остальных и возвращает готовый кусок. Главный агент не читает файл вообще, только координирует.

## Как это выглядит в Claude Code

Запускаю три Task tool параллельно:

```
Task(
  subagent_type: "general-purpose",
  prompt: "Прочитай subtitles.srt строки 1-4000.
           Сгенерируй конспект для глав 1-9.
           Формат: ### Глава + тезис + детали + цитата."
)

Task(
  subagent_type: "general-purpose",
  prompt: "Прочитай subtitles.srt строки 4000-8000.
           Сгенерируй конспект для глав 10-18."
)

Task(
  subagent_type: "general-purpose",
  prompt: "Прочитай subtitles.srt строки 8000-12800.
           Сгенерируй конспект для глав 19-26."
)
```

Три вызова в одном сообщении — Claude Code запускает их параллельно. Каждый субагент работает в своём контексте, читает свой кусок, генерирует свою часть.

Результат — три блока текста, которые склеиваю в один файл.

## Что получилось

| Метрика | Последовательно | MapReduce |
|---------|-----------------|-----------|
| Контекст главного агента | 100% (переполнен) | ~30% |
| Время выполнения | Не завершилось | ~3 минуты |
| Результат | Обрыв на середине | 26 глав конспекта |

Последовательное чтение упёрлось в лимит. Параллельное — работает.

## Когда использовать

Подходит:
- Файл больше 5000 строк
- Задача разбивается на независимые куски
- Результаты можно склеить без потери смысла

Не подходит:
- Куски зависят друг от друга
- Нужен общий контекст между частями
- Файл маленький — overhead не окупится

{{< callout warning "Overhead" >}}
Каждый субагент стоит ~20k токенов на запуск. Три субагента — 60k. На маленьких задачах это может быть дороже, чем просто прочитать файл.
{{< /callout >}}

## Почему это работает

Принцип из Go: «Share memory by communicating, don't communicate by sharing memory». Не пытайся впихнуть всё в один контекст. Раздай работу, собери результаты.

Anthropic пишут, что в их research-системе субагенты — это способ сжатия. Каждый исследует свой кусок, возвращает только важное. Главный агент не тонет в деталях.

То же самое с файлами. В моём случае: 12800 строк субтитров превратились в 460 строк конспекта. Компрессия примерно 28:1.

## Источники

- [How we built our multi-agent research system](https://www.anthropic.com/engineering/multi-agent-research-system) — Anthropic Engineering
- [Developer's guide to multi-agent patterns in ADK](https://developers.googleblog.com/developers-guide-to-multi-agent-patterns-in-adk/) — Google Developers
- [Context Engineering for AI Agents: Part 2](https://www.philschmid.de/context-engineering-part-2) — Phil Schmid
- [How to Use Claude Code Subagents to Parallelize Development](https://zachwills.net/how-to-use-claude-code-subagents-to-parallelize-development/) — Zach Wills
- [Multi-agent parallel coding with Claude Code](https://medium.com/@codecentrevibe/claude-code-multi-agent-parallel-coding-83271c4675fa) — Cuong Tham
