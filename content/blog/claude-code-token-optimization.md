---
title: "Куда уходят токены в Claude Code"
date: 2026-02-07
description: "Проанализировал 22 сессии за день. 95% контекста жрут результаты тулов, а не код в ответах. Пять приёмов которые реально экономят."
tags: ["claude-code", "оптимизация", "контекст", "токены", "вайбкодинг"]
---

95% контекста в Claude Code — не код. Не ответы агента. Результаты тулов. Я проверил на своих логах.

## Как я это выяснил

Вчера заметил: сессия на 400 промптов, а агент ни разу не уткнулся в лимит контекста. При этом ощущение — терминал забит мусором. Diff'ы после каждого Edit, простыни из WebFetch, результаты поиска.

Решил разобраться. Написал скрипт на Python, который парсит `~/.claude/projects/` — там Claude Code хранит логи в JSONL. Каждый блок разговора: мой промпт, ответ агента, результат инструмента. Скрипт считает размер каждого блока и группирует.

Взял вчерашний день. 22 сессии, четыре проекта. 920 вызовов инструментов.

## Что показали данные

```
КОНТЕКСТ ЗА ДЕНЬ (~616K токенов):

███████████████████████████████████████████████ 95.5%  Tool results
██                                              4.0%  Текст агента
░                                               0.5%  Код в ответах
```

Код в ответах — 17 блоков за весь день. Семнадцать. На фоне 920 вызовов инструментов.

219 результатов тулов оказались больше 2K символов, из них 25 — больше 10K. Один Read файла на 5000 строк съедает больше контекста, чем все ответы агента за час.

Вот топ по количеству вызовов:

```
Task ─────────── 110  субагенты
Bash ─────────── 83   git, тесты
Edit ─────────── 76   правки файлов
Read ─────────── 74   чтение файлов
Exa search ───── 29   поиск в вебе
WebFetch ─────── 20   загрузка страниц
```

Ни одной авто-компакции за день. Ноль. Потому что я начинаю новые сессии до того, как контекст разрастётся.

## Пять приёмов

### 1. Правило двух фейлов

Агент ошибся второй раз подряд в одной задаче — не дебажу. `/clear`. Новая сессия. Точный промпт.

Почему это работает: при дебаге агент перечитывает предыдущие попытки, результаты тулов, логи. Два Read по 3K строк плюс контекст прошлых ошибок — легко 20-30K токенов на то, чтобы разобраться что пошло не так.

Новая сессия — ноль багажа. "В auth.js проверь JWT валидацию, должна возвращать 401 на expired токен." Агент читает один файл, правит, тест проходит.

По-моему, это самый недооценённый приём. Все пытаются дожать сессию, хотя новая стоит ровно ноль.

### 2. Субагенты для тяжёлых операций

Task tool запускает отдельного агента с чистым контекстом. Тот копается в файлах, а родитель получает сжатый результат — 50-200 строк вместо тысяч.

Когда использую:
- Анализ больших файлов. Логи, документация, JSON-дампы.
- Исследования. "Изучи как работает obsws-python EventClient — какие события доступны". Субагент читает 8000+ строк документации, возвращает список на 150 строк.

Похожий [двухэтапный подход для экономии](/blog/two-stage-ai-pipeline) я использовал раньше в Telegram-боте — дешёвая модель извлекает, дорогая генерирует. Тут принцип тот же: субагент фильтрует, родитель работает с результатом.

### 3. Конкретные промпты

"Проверь мой код на баги" — агент читает весь проект. 15-20 вызовов Read, 50-70K токенов.

"В auth.js проверь JWT валидацию" — один файл, 3K токенов.

Если не знаю где проблема — разбиваю на два шага. Сначала: "найди файл где обрабатывается авторизация". Потом `/clear` и новый промпт с конкретным файлом. Цепочка "найди → новая сессия → исправь" дешевле, потому что результаты поиска не тащатся в контекст исправления.

### 4. Plan mode перед дорогими операциями

Shift+Tab. Агент пишет план вместо того чтобы делать. Читаю, правлю если нужно, одобряю.

Использую для рефакторинга на 5+ файлов, миграций, изменений в API. План стоит 2-5K токенов. Неудачная реализация которую потом откатываешь — в десять раз больше.

Бонус: в плане видно что агент собирается делать. Ловлю проблемы до выполнения, не после. Подробнее про то как [учить агента не повторять ошибки](/blog/fix-once-rule-forever) — отдельная история.

### 5. Мониторинг через ccusage

[ccusage](https://github.com/ryoppippi/ccusage) — CLI для анализа логов Claude Code. Показывает токены по проектам, сессиям, дням.

```
npm install -g ccusage
ccusage
```

Нашёл через него что в одном проекте CLAUDE.md весил 800 токенов. Он подгружается к каждому промпту. Сократил до 150 — минус 650 токенов на каждое обращение. За 50 промптов в сессии это 32K токенов.

`/usage` прямо в Claude Code показывает текущее использование. Смотрю когда близко к лимиту.

## Что не помогает

**Output styles типа "пиши короче".** Текст агента — 4% контекста. Код в ответах — полпроцента. Даже если агент замолчит совсем, 95% контекста никуда не денутся. Output style оптимизирует не то.

**"verbose: false" в CLAUDE.md.** Агент будет писать меньше текста в ответе. Но файлы всё равно читает целиком — это tool result, инструкция на него не влияет.

**Ручная компакция.** `/compact` сжимает контекст, но если сессии короткие (как у меня — `/clear` при каждой смене задачи), до порога компакции просто не доходит.

## Итог

Контекст в Claude Code — это на 95% результаты инструментов. Read, Bash, WebFetch, Exa. Не код в ответах, не текст агента.

Что реально экономит:
- `/clear` при двух фейлах — новая сессия дешевле дебага
- Субагенты для анализа больших файлов
- Конкретные промпты с именем файла
- Plan mode перед рефакторингом
- ccusage для поиска дорогих паттернов

Оптимизируй то, что занимает 95%. Не то, что занимает 4%.

---

*Данные: 6 февраля 2026, Claude Code на Opus 4.6, 22 сессии в 4 проектах.*
