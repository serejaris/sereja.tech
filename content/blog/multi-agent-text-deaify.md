---
title: "Как убрать аишность из текста: параллельные критики вместо одного rewriter"
date: 2026-01-11
description: "Один агент раздувает текст и оставляет AI-маркеры. Три параллельных критика + rewriter с hard rules — и текст становится человечным."
tags: ["claude code", "agents"]
section: AI
knowledge:
  problem: "Один AI-rewriter раздувает текст на 50% и оставляет те же AI-маркеры вместо их удаления."
  solution: "Три параллельных критика находят разные проблемы, затем rewriter с hard rules исправляет их по конкретному списку."
  pattern: "multi-agent-parallel-critics"
  tools: ["Claude Code", "Task tool", "Haiku"]
  takeaways:
    - "Один rewriter увеличивает текст на 50%, три критика + rewriter сокращают на 10%"
    - "Три haiku-агента работают параллельно за 10 секунд (~500 input tokens на критика)"
    - "AI-детекторы ищут perplexity и burstiness — простое перефразирование не помогает"
    - "Паттерн переносится на code review, редактуру документации, проверку спецификаций"
  metrics:
    text_bloat_single_rewriter_percent: 50
    text_reduction_multi_agent_percent: 10
    critics_count: 3
    parallel_time_seconds: 10
---

Попросил Claude переписать текст "более человечно".

Получил на 50% длиннее с теми же AI-маркерами.

## Почему один rewriter не работает

Когда просишь AI "сделать текст человечнее", он раздувает контент и заменяет одни паттерны на другие.

Протестировал на статье о Tailwind. Оригинал — 320 слов, после "humanize" — 500+. При этом остались фразы типа "И эта нога — хрупкая" и равномерные абзацы по 3-4 предложения.

AI-детекторы ищут perplexity (предсказуемость слов) и burstiness (ритм предложений). Один rewriter не фиксит ни то, ни другое — он просто перефразирует.

## Мульти-агентный подход

Три критика находят разные проблемы, rewriter их чинит по списку.

```
Текст → 3 параллельных критика → агрегация → rewriter с hard rules
```

**Generic Detector** ищет "важно понимать", "это не X — это Y", абстрактные claims без примеров.

**Rhythm Analyzer** находит монотонные списки, предложения одинаковой длины, повторяющиеся начала.

Третий критик показывает где добавить личный опыт, дату, имя, мнение.

Критиков запускаю параллельно через Task tool в Claude Code. Три haiku-агента работают одновременно — ~500 input tokens на критика, ~300 на выходе. Вся критика за 10 секунд вместо последовательных минут.

## Hard rules для rewriter

После агрегации критики rewriter получает конкретные ограничения:

Длина должна остаться ≤ оригинала. Без этого правила AI добавит "ценный контекст".

Каждую помеченную generic-фразу надо убить. Не перефразировать — убить.

Один личный touch обязателен. Варьировать длину предложений — от коротких до развёрнутых.

## Результат на реальном тексте

| Метрика | Один rewriter | 3 критика + rewriter |
|---------|---------------|----------------------|
| Длина | +50% (раздул) | -10% (сократил) |
| "Это не X — это Y" | Остались | Убраны |
| Личный опыт | Нет | "Я сам перестал..." |
| Имена/даты | Нет | Adam Wathan, конец 2024 |

## Как повторить

Сделал это скиллом для Claude Code в начале января. Триггеры: "деаишь", "убери аишность", "humanize".

```
~/.claude/skills/deaify-text/SKILL.md
```

Внутри — промпты для трёх критиков, hard rules для rewriter, таблица рационализаций (почему нельзя "просто один раз переписать").

Паттерн переносится на любой workflow где нужна критика: code review, редактура документации, проверка спецификаций. Разделяй анализ на независимых агентов, агрегируй, применяй с ограничениями.

## Источники

- [Multi-Agentic Workflow for Prompt Instructions Optimization (2026)](https://arxiv.org/html/2601.03359v1)
- [7 Multi-Agent Patterns Every Developer Needs in 2026](https://medium.com/@yadavdivy296/7-multi-agent-patterns-every-developer-needs-in-2026-and-how-to-pick-the-right-one-e8edcd99c96a)
- [Addy Osmani — My LLM coding workflow going into 2026](https://addyo.substack.com/p/my-llm-coding-workflow-going-into)
